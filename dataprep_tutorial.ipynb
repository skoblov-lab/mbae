{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation usage and examples.\n",
    "\n",
    "This notebook showcases two ways of interacting with the `mbae` data preparation code.\n",
    "\n",
    "\n",
    "The `mbae.py prepare` command covers the most of the user needs in data preparation (see the first section).\n",
    "\n",
    "`mbae` also provides useful interface (see the second section) for programmatic access to the data preparation routines.\n",
    "\n",
    "\n",
    "## 1. Access via `mbae.py` interface.\n",
    "\n",
    "`mbae.py` has several commands, each having a collection of options.\n",
    "Let's look at the commands first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usage: mbae.py [OPTIONS] COMMAND [ARGS]...\n",
      "\n",
      "Options:\n",
      "  -h, --help  Show this message and exit.\n",
      "\n",
      "Commands:\n",
      "  alleles  List all supported alleles\n",
      "  predict  Predict binding affinity\n",
      "  prepare  Prepare mbae resources\n"
     ]
    }
   ],
   "source": [
    "! python mbae.py --help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then we'll look at the subcommands of the `prepare` command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usage: mbae.py prepare [OPTIONS] COMMAND [ARGS]...\n",
      "\n",
      "  Prepare mbae resources\n",
      "\n",
      "Options:\n",
      "  -h, --help  Show this message and exit.\n",
      "\n",
      "Commands:\n",
      "  dataset    Prepare training dataset\n",
      "  sequences  Prepare allotype sequences\n"
     ]
    }
   ],
   "source": [
    "! python mbae.py prepare --help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, there are two possible data types to prepaare with `mbae`: (1) dataset holding the training observations and (2) allotype sequences.\n",
    "\n",
    "First, we'll go ahead and look at how does one prepare the training data.\n",
    "\n",
    "### 1.1 Preparing training observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usage: mbae.py prepare dataset [OPTIONS]\n",
      "\n",
      "  Prepare training dataset\n",
      "\n",
      "Options:\n",
      "  -d, --download_dir DIRECTORY    Path to a download directory  [default: ./]\n",
      "  -D, --database TEXT             Databases to prepare. Supports multiple\n",
      "                                  values. Use `--database iedb` or `--database\n",
      "                                  bdata` to download and prepare IEDB or\n",
      "                                  Bdata, separately. Currently, available\n",
      "                                  resources are: iedb and bdata, while \"all\"\n",
      "                                  and \"none\" values are reserved for parsing\n",
      "                                  all or none data sources, respectively.\n",
      "                                  [default: all]\n",
      "\n",
      "  -m, --mapping FILE              Path to mapping: a headerless file with\n",
      "                                  space-like separator (e.g., \\t) holding\n",
      "                                  mappings between allele names (1st column)\n",
      "                                  and accessions (2nd column). Accessions must\n",
      "                                  be from IPD-MHC (for non-human alleles) or\n",
      "                                  IMGT/HLA (for human alleles).If not\n",
      "                                  provided, the command will download and\n",
      "                                  parse mappings from the aforementioned\n",
      "                                  resources and manually add mice alleles.\n",
      "\n",
      "  -s, --save TEXT                 Option controls what will be saved. Multiple\n",
      "                                  values are supported: - final (final data\n",
      "                                  will be saved); - parsed (every parsed\n",
      "                                  Resource will be saved); - mapping (the\n",
      "                                  obtained mapping will be saved); - raw (raw\n",
      "                                  downloaded files will be saved). Example:\n",
      "                                  \"-s parsed -s final\" to save parsed data of\n",
      "                                  used resources along with the final dataset.\n",
      "                                  [default: final]\n",
      "\n",
      "  -S, --separate_rare             Whether to separate the resulting DataFrame\n",
      "                                  into two parts - \"abundant\" and \"rare.\" If\n",
      "                                  provided, each of the \"abundant\" and \"rare\"\n",
      "                                  subsets will also be separated into a\n",
      "                                  \"train\" and \"test\" subsets based on\n",
      "                                  `sep_fraction` value.  [default: False]\n",
      "\n",
      "  -t, --rare_threshold INTEGER    If the `separate_rare` flag is provided, use\n",
      "                                  this threshold to control the placement into\n",
      "                                  \"abundant\" and \"rare\" subsets.  [default:\n",
      "                                  100]\n",
      "\n",
      "  -f, --sep_fraction FLOAT        A fraction of training examples to separate.\n",
      "                                  [default: 0.8]\n",
      "\n",
      "  -M, --sep_mode [observations|allotypes]\n",
      "                                  A separation mode. If `observation`, will\n",
      "                                  separate a `sep_fraction` of unique\n",
      "                                  allotype-peptide pairs. If `allotypes`, will\n",
      "                                  separate a `sep_fraction` of unique\n",
      "                                  allotypes.   [default: observations]\n",
      "\n",
      "  -c, --cutoffs TEXT              Cutoffs are used by mbae while converting\n",
      "                                  affinity values between continuous and ord\n",
      "                                  domains. Thus, mbae will assign measurements\n",
      "                                  between cutoff values a single class: 1 for\n",
      "                                  10-100, 2 for 100-500, and so on.  [default:\n",
      "                                  10,100,500,2500,10000,20000]\n",
      "\n",
      "  -v, --verbose                   If the flag is provided, will output logging\n",
      "                                  messages with the info describing main data\n",
      "                                  processing steps. By default, outputs only\n",
      "                                  warnings.   [default: False]\n",
      "\n",
      "  -h, --help                      Show this message and exit.\n"
     ]
    }
   ],
   "source": [
    "! python mbae.py prepare dataset --help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mapping between allotype names and accessions is mandatory. \n",
    "It serves as a way to disambiguate different allotype naming conventions. Given a concrete allotype, all of the (historical and current) names (ideally) point to the same accession within IEDB.\n",
    "\n",
    "Suppose one wants to prepare only mapping between accession and allotypes and save it into the current directory.\n",
    "Thus, one would use `prepare` in the following manner:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mbae.py prepare dataset --database none --save mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HLA-A*01:01\tHLA27590\n",
      "HLA-A*01010101\tHLA00001\n",
      "HLA-A*010101\tHLA00001\n",
      "HLA-A*01011\tHLA00001\n",
      "HLA-A*0101\tHLA00001\n",
      "HLA-A*01:02\tHLA26566\n",
      "HLA-A*0102\tHLA00002\n",
      "HLA-A*01:03\tHLA23245\n",
      "HLA-A*0103\tHLA00003\n",
      "HLA-A*01:04\tHLA18724\n"
     ]
    }
   ],
   "source": [
    "! head mapping.tsv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One can observe that the file `mapping.tsv` has appeared in the current directory.\n",
    "\n",
    "Since we've already obtained the mapping between accessions and allotypes, we can use it to prepare the IEDB resource. \n",
    "Let's also save raw and parsed files into the `./tmp` directory (should be created beforehand)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir -p ./tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:root:IEDB -- could not map 46 allotypes ['Anpl-UAA*01' 'BF2*0401' 'BF2*1201' 'ELA-A1 class I' 'Eqca-N*00602'\n",
      " 'FLA-E*01801' 'H2-Db H155A mutant' 'H2-Db Y159F mutant'\n",
      " 'H2-Kb D77S, K89A mutant' 'H2-Kb E152A, R155Y, L156Y mutant'\n",
      " 'H2-Kb Y22F, M23I, E24S, D30N mutant' 'H2-Kb Y84A mutant'\n",
      " 'H2-Kb Y84C mutant' 'H2-Lq' 'H2-d class I' 'HLA class I'\n",
      " 'HLA-A*02:01 K66A mutant' 'HLA-A*02:01 K66A, E63Q mutant' 'HLA-A1'\n",
      " 'HLA-A11' 'HLA-A2' 'HLA-A24' 'HLA-A26' 'HLA-A3' 'HLA-A68'\n",
      " 'HLA-B*08:01 B:I66A mutant' 'HLA-B*08:01 E76C mutant' 'HLA-B27' 'HLA-B39'\n",
      " 'HLA-B40' 'HLA-B44' 'HLA-B51' 'HLA-B58' 'HLA-B60' 'HLA-B62' 'HLA-B7'\n",
      " 'HLA-B8' 'HLA-Cw1' 'HLA-Cw4' 'Mamu-B*001:01' 'Mamu-B*003:01'\n",
      " 'Ptal-N*01:01' 'RT1-Aa' 'SLA-1*04:01' 'SLA-3*02:02' 'Xela-UAAg'] corresponding to 1113 records\n"
     ]
    }
   ],
   "source": [
    "! mbae.py prepare dataset -d ./tmp -m ./mapping.tsv -D iedb -s raw -s parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IEDB_parsed.tsv      mhc_ligand_full.zip\n"
     ]
    }
   ],
   "source": [
    "ls ./tmp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, the `./tmp` directory now contains both raw and parsed files, as well as training and testing data.\n",
    "\n",
    "Now, we can also prepare both Bdata2013 and IEDB datasets.\n",
    "In this case, `mbae` will merge these data sources, appending unique Bdata allele-peptide observations to all IEDB ones.\n",
    "Let's also make the data preparation verbose so we can clearly see how filtering and merging operations affect the number of entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:root:IEDB -- successfully initialized resource\n",
      "INFO:root:IEDB -- downloaded resource from https://www.iedb.org/downloader.php?file_name=doc/mhc_ligand_full_single_file.zip\n",
      "INFO:root:IEDB -- loaded resource; records: 1883298\n",
      "INFO:root:IEDB -- filtered class I records; records: 1621944\n",
      "INFO:root:IEDB -- filtered quantitative assays; records: 184623\n",
      "INFO:root:IEDB -- filtered quantitative measurements; records: 157525\n",
      "INFO:root:IEDB -- filtered by evidence codes; records: 157525\n",
      "INFO:root:IEDB -- filtered by antigen type; records: 157521\n",
      "INFO:root:IEDB -- filtered by peptide length; records: 157111\n",
      "WARNING:root:IEDB -- could not map 46 allotypes ['Anpl-UAA*01' 'BF2*0401' 'BF2*1201' 'ELA-A1 class I' 'Eqca-N*00602'\n",
      " 'FLA-E*01801' 'H2-Db H155A mutant' 'H2-Db Y159F mutant'\n",
      " 'H2-Kb D77S, K89A mutant' 'H2-Kb E152A, R155Y, L156Y mutant'\n",
      " 'H2-Kb Y22F, M23I, E24S, D30N mutant' 'H2-Kb Y84A mutant'\n",
      " 'H2-Kb Y84C mutant' 'H2-Lq' 'H2-d class I' 'HLA class I'\n",
      " 'HLA-A*02:01 K66A mutant' 'HLA-A*02:01 K66A, E63Q mutant' 'HLA-A1'\n",
      " 'HLA-A11' 'HLA-A2' 'HLA-A24' 'HLA-A26' 'HLA-A3' 'HLA-A68'\n",
      " 'HLA-B*08:01 B:I66A mutant' 'HLA-B*08:01 E76C mutant' 'HLA-B27' 'HLA-B39'\n",
      " 'HLA-B40' 'HLA-B44' 'HLA-B51' 'HLA-B58' 'HLA-B60' 'HLA-B62' 'HLA-B7'\n",
      " 'HLA-B8' 'HLA-Cw1' 'HLA-Cw4' 'Mamu-B*001:01' 'Mamu-B*003:01'\n",
      " 'Ptal-N*01:01' 'RT1-Aa' 'SLA-1*04:01' 'SLA-3*02:02' 'Xela-UAAg'] corresponding to 1113 records\n",
      "INFO:root:IEDB -- filtered out unmapped allotypes; records: 155998\n",
      "INFO:root:IEDB -- dropped unnecessary columns and removed duplicates; records 153814\n",
      "INFO:root:IEDB -- completed resource preparation; records: 153814\n",
      "INFO:root:Bdata -- successfully initialized resource\n",
      "INFO:root:Bdata -- downloaded resource from http://tools.iedb.org/static/main/binding_data_2013.zip\n",
      "INFO:root:Bdata -- loaded resource; records: 186684\n",
      "INFO:root:Bdata -- filtered by peptide length; records: 186602\n",
      "WARNING:root:Bdata -- could not map 44 allotypes ['BoLA-AW10' 'BoLA-D18.4' 'BoLA-HD6' 'BoLA-JSP.1' 'BoLA-T2C' 'BoLA-T2a'\n",
      " 'BoLA-T2b' 'ELA-A1' 'H-2-Kbm8' 'H-2-Lq' 'HLA-A1' 'HLA-A11' 'HLA-A2'\n",
      " 'HLA-A24' 'HLA-A26' 'HLA-A3' 'HLA-A3/11' 'HLA-B27' 'HLA-B44' 'HLA-B51'\n",
      " 'HLA-B60' 'HLA-B7' 'HLA-B8' 'HLA-Cw1' 'HLA-Cw4' 'Mamu-A*01' 'Mamu-A*02'\n",
      " 'Mamu-A*07' 'Mamu-A*11' 'Mamu-A*2201' 'Mamu-A*2601' 'Mamu-B*01'\n",
      " 'Mamu-B*03' 'Mamu-B*04' 'Mamu-B*08' 'Mamu-B*1001' 'Mamu-B*17'\n",
      " 'Mamu-B*3901' 'Mamu-B*52' 'Mamu-B*6601' 'Mamu-B*8301' 'Mamu-B*8701'\n",
      " 'RT1-Bl' 'RT1A'] corresponding to 15453 records\n",
      "INFO:root:Bdata -- filtered out unmapped allotypes; records: 171149\n",
      "INFO:root:Bdata -- dropped unnecessary columns and removed duplicates; records 171149\n",
      "INFO:root:Bdata -- completed resource preparation; records: 171149\n",
      "INFO:root:Combined data sources; records: 185835\n",
      "INFO:root:Removed duplicated measurements; records: 181832\n",
      "INFO:root:Saved 145412 training and 36420 testing observations.\n"
     ]
    }
   ],
   "source": [
    "! mbae.py prepare dataset -d ./tmp -m mapping.tsv --verbose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IEDB_parsed.tsv      test_data.tsv\n",
      "mhc_ligand_full.zip  train_data.tsv\n"
     ]
    }
   ],
   "source": [
    "ls ./tmp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some allotypes have a small number of observations.\n",
    "One may want to separate the parsed data as beloning to \"abundant\" and \"rare\" MHC alleles.\n",
    "This is easily done by providing the `--separate_rare` or `-S` flag.\n",
    "In this case, since we did not provide the mapping, the logging will output the `IMGTHLA` and `IPDMHC` parsing steps first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:root:IMGT/HLA history -- successfully initialized resource\n",
      "INFO:root:IPD-MHC history -- successfully initialized resource\n",
      "INFO:root:IMGT/HLA history -- downloaded resource from https://raw.githubusercontent.com/ANHIG/IMGTHLA/Latest/Allelelist_history.txt\n",
      "INFO:root:IMGT/HLA history -- successfully extracted mappings\n",
      "INFO:root:IPD-MHC history -- downloaded resource from https://raw.githubusercontent.com/ANHIG/IPDMHC/Latest/MHC.xml\n",
      "INFO:root:IPD-MHC history -- parsed xml tree\n",
      "INFO:root:IPD-MHC history -- successfully extracted mappings\n",
      "INFO:root:IEDB -- successfully initialized resource\n",
      "INFO:root:IEDB -- downloaded resource from https://www.iedb.org/downloader.php?file_name=doc/mhc_ligand_full_single_file.zip\n",
      "INFO:root:IEDB -- loaded resource; records: 1883298\n",
      "INFO:root:IEDB -- filtered class I records; records: 1621944\n",
      "INFO:root:IEDB -- filtered quantitative assays; records: 184623\n",
      "INFO:root:IEDB -- filtered quantitative measurements; records: 157525\n",
      "INFO:root:IEDB -- filtered by evidence codes; records: 157525\n",
      "INFO:root:IEDB -- filtered by antigen type; records: 157521\n",
      "INFO:root:IEDB -- filtered by peptide length; records: 157111\n",
      "WARNING:root:IEDB -- could not map 46 allotypes ['Anpl-UAA*01' 'BF2*0401' 'BF2*1201' 'ELA-A1 class I' 'Eqca-N*00602'\n",
      " 'FLA-E*01801' 'H2-Db H155A mutant' 'H2-Db Y159F mutant'\n",
      " 'H2-Kb D77S, K89A mutant' 'H2-Kb E152A, R155Y, L156Y mutant'\n",
      " 'H2-Kb Y22F, M23I, E24S, D30N mutant' 'H2-Kb Y84A mutant'\n",
      " 'H2-Kb Y84C mutant' 'H2-Lq' 'H2-d class I' 'HLA class I'\n",
      " 'HLA-A*02:01 K66A mutant' 'HLA-A*02:01 K66A, E63Q mutant' 'HLA-A1'\n",
      " 'HLA-A11' 'HLA-A2' 'HLA-A24' 'HLA-A26' 'HLA-A3' 'HLA-A68'\n",
      " 'HLA-B*08:01 B:I66A mutant' 'HLA-B*08:01 E76C mutant' 'HLA-B27' 'HLA-B39'\n",
      " 'HLA-B40' 'HLA-B44' 'HLA-B51' 'HLA-B58' 'HLA-B60' 'HLA-B62' 'HLA-B7'\n",
      " 'HLA-B8' 'HLA-Cw1' 'HLA-Cw4' 'Mamu-B*001:01' 'Mamu-B*003:01'\n",
      " 'Ptal-N*01:01' 'RT1-Aa' 'SLA-1*04:01' 'SLA-3*02:02' 'Xela-UAAg'] corresponding to 1113 records\n",
      "INFO:root:IEDB -- filtered out unmapped allotypes; records: 155998\n",
      "INFO:root:IEDB -- dropped unnecessary columns and removed duplicates; records 153814\n",
      "INFO:root:IEDB -- completed resource preparation; records: 153814\n",
      "INFO:root:Bdata -- successfully initialized resource\n",
      "INFO:root:Bdata -- downloaded resource from http://tools.iedb.org/static/main/binding_data_2013.zip\n",
      "INFO:root:Bdata -- loaded resource; records: 186684\n",
      "INFO:root:Bdata -- filtered by peptide length; records: 186602\n",
      "WARNING:root:Bdata -- could not map 44 allotypes ['BoLA-AW10' 'BoLA-D18.4' 'BoLA-HD6' 'BoLA-JSP.1' 'BoLA-T2C' 'BoLA-T2a'\n",
      " 'BoLA-T2b' 'ELA-A1' 'H-2-Kbm8' 'H-2-Lq' 'HLA-A1' 'HLA-A11' 'HLA-A2'\n",
      " 'HLA-A24' 'HLA-A26' 'HLA-A3' 'HLA-A3/11' 'HLA-B27' 'HLA-B44' 'HLA-B51'\n",
      " 'HLA-B60' 'HLA-B7' 'HLA-B8' 'HLA-Cw1' 'HLA-Cw4' 'Mamu-A*01' 'Mamu-A*02'\n",
      " 'Mamu-A*07' 'Mamu-A*11' 'Mamu-A*2201' 'Mamu-A*2601' 'Mamu-B*01'\n",
      " 'Mamu-B*03' 'Mamu-B*04' 'Mamu-B*08' 'Mamu-B*1001' 'Mamu-B*17'\n",
      " 'Mamu-B*3901' 'Mamu-B*52' 'Mamu-B*6601' 'Mamu-B*8301' 'Mamu-B*8701'\n",
      " 'RT1-Bl' 'RT1A'] corresponding to 15453 records\n",
      "INFO:root:Bdata -- filtered out unmapped allotypes; records: 171149\n",
      "INFO:root:Bdata -- dropped unnecessary columns and removed duplicates; records 171149\n",
      "INFO:root:Bdata -- completed resource preparation; records: 171149\n",
      "INFO:root:Combined data sources; records: 185835\n",
      "INFO:root:Removed duplicated measurements; records: 181832\n",
      "INFO:root:Saved 143818 training and 36144 testing observations for the abundant subset.\n",
      "INFO:root:Saved 1497 training and 373 testing observations for the rare subset.\n"
     ]
    }
   ],
   "source": [
    "! mbae.py prepare dataset -d ./tmp -v -S"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a result, we have four new files appearing in the `./tmp` directory: `train/test_abundant.tsv` and `train/test_rare.tsv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IEDB_parsed.tsv          test_data_abundant.tsv   train_data_abundant.tsv\n",
      "mhc_ligand_full.zip      test_data_rare.tsv       train_data_rare.tsv\n",
      "test_data.tsv            train_data.tsv\n"
     ]
    }
   ],
   "source": [
    "ls ./tmp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Preparing sequences.\n",
    "`mbae` is trained on both peptide and allotype sequences.\n",
    "Training dataset by default includes the former.\n",
    "Thus, `mbae` provides interface to prepare the latter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usage: mbae.py prepare sequences [OPTIONS]\n",
      "\n",
      "  Prepare allotype sequences\n",
      "\n",
      "Options:\n",
      "  -d, --download_dir DIRECTORY  Path to a download directory.  [default: ./]\n",
      "  -o, --output TEXT             Output file name for the final data.\n",
      "                                [default: sequences.fasta]\n",
      "\n",
      "  -s, --save TEXT               An option controlling what will be saved.\n",
      "                                Multiple values are supported: - final (final\n",
      "                                data will be saved); - parsed (every parsed\n",
      "                                Resource will be saved); - raw (raw downloaded\n",
      "                                files will be saved). Example: \"-s parsed -s\n",
      "                                final\" to save parsed data of used resources\n",
      "                                along with the final data.   [default: final]\n",
      "\n",
      "  -a, --accessions TEXT         A list of comma-separated accessions.\n",
      "  -f, --accessions_file FILE    A path to a file holding a list of accessions,\n",
      "                                one per a line. If provided, the list provided\n",
      "                                via the `--accessions` option will be ignored.\n",
      "\n",
      "  -p, --profile FILE            Path to an MSA of binding regions. Mbae will\n",
      "                                use this MSA to cut sequences down to just\n",
      "                                MHC/HLA binding regions. If one does not want\n",
      "                                cutting sequences, `--profile None` should be\n",
      "                                passed.   [default:\n",
      "                                ./mbae_resources/binding_regions.fsa]\n",
      "\n",
      "  -t, --threads INTEGER         A number of threads to use for alignment.\n",
      "                                [default: 1]\n",
      "\n",
      "  -v, --verbose                 If the flag is provided, will output logging\n",
      "                                messages with the info describing main data\n",
      "                                processing steps. By default, outputs only\n",
      "                                warnings.   [default: False]\n",
      "\n",
      "  -h, --help                    Show this message and exit.\n"
     ]
    }
   ],
   "source": [
    "! mbae.py prepare sequences --help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As previously, the interface is fairly flexible. \n",
    "Here is what it can do for you:\n",
    "1. Download canonical allotype sequences from IMGT/HLA and IPD-MHC.\n",
    "2. Filter the downloaded sequences based on accessions.\n",
    "3. Align (using `mafft --add`) to our MSA encompassing MHC binding regions and cut sequences accordingly.\n",
    "\n",
    "We largely rely on IMGT/HLA and IPD-MHC in terms of sequences.\n",
    "Namely, we require that your allotype has a valid accession in the aformentioned resources.\n",
    "If it does, it is likely our alignment profile already contains this sequences, and `mbae` will pull if from there.\n",
    "Otherwise, it will be aligned to the MSA and cut.\n",
    "However, one can bypass both filtering and cutting by passing no accessions and using `--profile none` option (e.g., when one wants just to download the raw data), respectively.\n",
    "We'll show these usecases below.\n",
    "\n",
    "Let's start by downloading the raw data into the `./tmp`. In this case, we'll omit filtering by accessions and cutting by profile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/ivanreveguk/Projects/mbae_git/none\n"
     ]
    }
   ],
   "source": [
    "! mbae.py prepare sequences -d ./tmp -s raw -p none"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IEDB_parsed.tsv         test_data.tsv           train_data_abundant.tsv\n",
      "MHC_prot.fasta          test_data_abundant.tsv  train_data_rare.tsv\n",
      "hla_prot.fasta          test_data_rare.tsv\n",
      "mhc_ligand_full.zip     train_data.tsv\n"
     ]
    }
   ],
   "source": [
    "! ls ./tmp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll filter by accessions while omitting the alignment.\n",
    "A small number of accessions can be passed as a comma-separated list.\n",
    "\n",
    "In this case, however, `mbae` will filter out accessions missing in both IPD-MHC and IMGT/HLA databases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/ivanreveguk/Projects/mbae_git/none\n",
      "INFO:root:IPD-MHC sequences -- successfully initialized resource\n",
      "INFO:root:IMGT/HLA sequences -- successfully initialized resource\n",
      "INFO:root:IPD-MHC sequences -- downloaded resource from https://raw.githubusercontent.com/ANHIG/IPDMHC/Latest/MHC_prot.fasta\n",
      "INFO:root:IMGT/HLA sequences -- downloaded resource from https://raw.githubusercontent.com/ANHIG/IMGTHLA/Latest/hla_prot.fasta\n",
      "INFO:root:IPD-MHC sequences -- loaded 10302 sequences\n",
      "INFO:root:IPD-MHC sequences -- filtered by accessions; 1 left (out of provided 6).\n",
      "WARNING:root:IPD-MHC sequences -- accessions HLA28165;HLA25912;H-2-Kk;HLA00222;HLA00009 were not found\n",
      "INFO:root:IPD-MHC sequences -- finished parsing sequences; 1 in total\n",
      "INFO:root:IMGT/HLA sequences -- loaded 27840 sequences\n",
      "INFO:root:IMGT/HLA sequences -- filtered by accessions; 4 left (out of provided 6).\n",
      "WARNING:root:IMGT/HLA sequences -- accessions H-2-Kk;NHP00709 were not found\n",
      "INFO:root:IMGT/HLA sequences -- finished parsing sequences; 4 in total\n",
      "INFO:root:IPD-MHC sequences -- saved parsed data to /Users/ivanreveguk/Projects/mbae_git/tmp/IPD-MHC_sequences.fasta\n",
      "INFO:root:IMGT/HLA sequences -- saved parsed data to /Users/ivanreveguk/Projects/mbae_git/tmp/IMGTHLA_sequences.fasta\n",
      "INFO:root:IPD-MHC+IMGT/HLA sequences -- saved parsed data to /Users/ivanreveguk/Projects/mbae_git/tmp/sequences.fasta\n"
     ]
    }
   ],
   "source": [
    "! mbae.py prepare sequences -d ./tmp -s parsed -s final -v -p none --accessions H-2-Kk,HLA25912,HLA00009,NHP00709,HLA00222,HLA28165"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To prepare a larger set of sequences, it's clearly better to put these into a single file first.\n",
    "Then provide `mbae` with a correct path to a file via `--accessions_file` or `-f` option."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_accessions = [\n",
    "    'ELA04973', 'HLA01173', 'HLA24796', 'HLA28069', 'BoLA03176',\n",
    "    'NHP01865', 'HLA27997', 'HLA27977', 'H-2-Kk', 'HLA25912',\n",
    "    'HLA00009', 'HLA27068', 'HLA16743', 'HLA27953', 'HLA15201',\n",
    "    'NHP00709', 'HLA00222', 'HLA28165', 'HLA25670', 'HLA25900']\n",
    "with open('./tmp/accessions.txt', 'w') as f:\n",
    "    print(*sample_accessions, sep='\\n', file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/ivanreveguk/Projects/mbae_git/mbae_resources/binding_regions.fsa\n",
      "INFO:root:IPD-MHC sequences -- successfully initialized resource\n",
      "INFO:root:IMGT/HLA sequences -- successfully initialized resource\n",
      "INFO:root:IPD-MHC sequences -- downloaded resource from https://raw.githubusercontent.com/ANHIG/IPDMHC/Latest/MHC_prot.fasta\n",
      "INFO:root:IMGT/HLA sequences -- downloaded resource from https://raw.githubusercontent.com/ANHIG/IMGTHLA/Latest/hla_prot.fasta\n",
      "INFO:root:IPD-MHC sequences -- loaded 10302 sequences\n",
      "INFO:root:IPD-MHC sequences -- filtered by accessions; 4 left (out of provided 21).\n",
      "INFO:root:IPD-MHC sequences -- 7 sequences were found in profile /Users/ivanreveguk/Projects/mbae_git/mbae_resources/binding_regions.fsa\n",
      "INFO:root:IPD-MHC sequences -- 1 will be aligned to /Users/ivanreveguk/Projects/mbae_git/mbae_resources/binding_regions.fsa\n",
      "Cutting sequences: 100%|██████████████████████████| 1/1 [00:05<00:00,  5.89s/it]\n",
      "WARNING:root:IPD-MHC sequences -- accessions ;HLA15201;HLA25912;HLA27977;HLA28069;HLA16743;HLA27953;HLA28165;HLA25670;HLA25900;HLA24796;HLA27997;HLA27068 were not found\n",
      "INFO:root:IPD-MHC sequences -- finished parsing sequences; 8 in total\n",
      "INFO:root:IMGT/HLA sequences -- loaded 27840 sequences\n",
      "INFO:root:IMGT/HLA sequences -- filtered by accessions; 15 left (out of provided 21).\n",
      "INFO:root:IMGT/HLA sequences -- 7 sequences were found in profile /Users/ivanreveguk/Projects/mbae_git/mbae_resources/binding_regions.fsa\n",
      "INFO:root:IMGT/HLA sequences -- 12 will be aligned to /Users/ivanreveguk/Projects/mbae_git/mbae_resources/binding_regions.fsa\n",
      "Cutting sequences: 100%|████████████████████████| 12/12 [01:06<00:00,  5.56s/it]\n",
      "WARNING:root:IMGT/HLA sequences -- accessions ;ELA04973 were not found\n",
      "INFO:root:IMGT/HLA sequences -- finished parsing sequences; 19 in total\n",
      "INFO:root:IPD-MHC+IMGT/HLA sequences -- saved parsed data to /Users/ivanreveguk/Projects/mbae_git/tmp/sequences.fasta\n"
     ]
    }
   ],
   "source": [
    "! mbae.py prepare sequences -d ./tmp -s final -v -f ./tmp/accessions.txt -t 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">BoLA03176 BoLA-2*00801\n",
      "SHSLRYFLTAVSRPGLGEPRFIIVGYVDDTQFVRFDSNTPNPRMEPRARWVEKEGPEYWD\n",
      "RETRNSKETAQTFRANLNTALGYYNQSEAGSHTVQEMYGCDVGPDGRLLRGFMQDAYDGR\n",
      "DYIALNEDLRSWTAADTAAQITKRKWEAAGDAETWRNYLEGRCVEWLRRYLENGKDALL\n",
      ">H-2-Kk H2-Kk\n",
      "PHSLRYFHTAVSRPGLGKPRFISVGYVDDTQFVRFDSDAENPRYEPRVRWMEQVEPEYWE\n",
      "RNTQIAKGNEQIFRVNLRTALRYYNQSAGGSHTFQRMYGCEVGSDWRLLRGYEQYAYDGC\n",
      "DYIALNEDLKTWTAADMAALITKHKWEQAGDAERDRAYLEGTCVEWLRRYLQLGNATLP\n",
      ">HLA00009 HLA-A*02:04\n",
      "SHSMRYFFTSVSRPGRGEPRFIAVGYVDDTQFVRFDSDAASQRMEPRAPWIEQEGPEYWD\n"
     ]
    }
   ],
   "source": [
    "! head ./tmp/sequences.fasta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And, finally, it is even possible to download and cut ALL the IPD-MHC and IMGT/HLA sequences.\n",
    "The command would be `mbae.py prepare sequences -d ./tmp`. \n",
    "It will download raw sequences into the `/tmp` (not the local `./tmp` since we did not pass `-s raw`) and cut each of them.\n",
    "This'll obviously take a long time and we aren't going to wait until completion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/ivanreveguk/Projects/mbae_git/mbae_resources/binding_regions.fsa\n",
      "INFO:root:IPD-MHC sequences -- successfully initialized resource\n",
      "INFO:root:IMGT/HLA sequences -- successfully initialized resource\n",
      "INFO:root:IPD-MHC sequences -- downloaded resource from https://raw.githubusercontent.com/ANHIG/IPDMHC/Latest/MHC_prot.fasta\n",
      "INFO:root:IMGT/HLA sequences -- downloaded resource from https://raw.githubusercontent.com/ANHIG/IMGTHLA/Latest/hla_prot.fasta\n",
      "INFO:root:IPD-MHC sequences -- loaded 10302 sequences\n",
      "WARNING:root:IPD-MHC sequences -- no accessions were provided. Are you certain you need all (10302) available sequences?\n",
      "INFO:root:IPD-MHC sequences -- 35 sequences were found in profile /Users/ivanreveguk/Projects/mbae_git/mbae_resources/binding_regions.fsa\n",
      "INFO:root:IPD-MHC sequences -- 10267 will be aligned to /Users/ivanreveguk/Projects/mbae_git/mbae_resources/binding_regions.fsa\n",
      "Cutting sequences:   0%|                              | 0/10267 [00:00<?, ?it/s]^C\n",
      "\n",
      "Aborted!\n",
      "Cutting sequences:   0%|                              | 0/10267 [00:03<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "! mbae.py prepare sequences -d ./tmp -v "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Programmatic access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO) # To display logging messages\n",
    "from random import sample\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from mbae_src.data.base import Constants\n",
    "from mbae_src.data.prepare import (\n",
    "    obtain_mapping, separate_abundant, separate_fraction, _dump_data, # Helper functions\n",
    "    IMGTHLAhistory, IPDMHChistory, # Objects to obtain an allotype->accession mapping\n",
    "    IMGTHLAsequences, IPDMHCsequences, # Objects to get sequences\n",
    "    IEDB, Bdata # Objects to parse observations from\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Obtaining mappings\n",
    "\n",
    "Let's first create a mapping object.\n",
    "If we don't need `IMGTHLAhistory`, `IPDMHChistory` objects, we can simply go ahead and call `obtain_mapping`.\n",
    "The latter only needs a directory path to store downloaded resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:IMGT/HLA history -- successfully initialized resource\n",
      "INFO:root:IMGT/HLA history -- downloaded resource from https://raw.githubusercontent.com/ANHIG/IMGTHLA/Latest/Allelelist_history.txt\n",
      "INFO:root:IMGT/HLA history -- successfully extracted mappings\n",
      "INFO:root:IPD-MHC history -- successfully initialized resource\n",
      "INFO:root:IPD-MHC history -- downloaded resource from https://raw.githubusercontent.com/ANHIG/IPDMHC/Latest/MHC.xml\n",
      "INFO:root:IPD-MHC history -- parsed xml tree\n",
      "INFO:root:IPD-MHC history -- successfully extracted mappings\n"
     ]
    }
   ],
   "source": [
    "mapping = obtain_mapping('./tmp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('HLA-A*01:01', 'HLA27590'),\n",
       " ('HLA-A*01010101', 'HLA00001'),\n",
       " ('HLA-A*010101', 'HLA00001'),\n",
       " ('HLA-A*01011', 'HLA00001'),\n",
       " ('HLA-A*0101', 'HLA00001')]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(mapping.items())[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, we can init `IMGTHLAhistory`, `IPDMHChistory` manually, like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:IMGT/HLA history -- successfully initialized resource\n",
      "INFO:root:IPD-MHC history -- successfully initialized resource\n"
     ]
    }
   ],
   "source": [
    "imgt_hist, ipd_hist = IMGTHLAhistory(), IPDMHChistory()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are `Resource`s, by default having three methods: `fetch`, `parse` and `dump`.\n",
    "Obviously, `parse` depends on `fetch`'s results, while `parse` must be called prior to `dump`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:IMGT/HLA history -- downloaded resource from https://raw.githubusercontent.com/ANHIG/IMGTHLA/Latest/Allelelist_history.txt\n",
      "INFO:root:IMGT/HLA history -- successfully extracted mappings\n",
      "INFO:root:IPD-MHC history -- downloaded resource from https://raw.githubusercontent.com/ANHIG/IPDMHC/Latest/MHC.xml\n",
      "INFO:root:IPD-MHC history -- parsed xml tree\n",
      "INFO:root:IPD-MHC history -- successfully extracted mappings\n"
     ]
    }
   ],
   "source": [
    "imgt_hist.fetch() \n",
    "imgt_hist.parse()\n",
    "ipd_hist.fetch()\n",
    "ipd_hist.parse();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Every resource has an attribute holding parsed data.\n",
    "For the `imgt` and `ipd` it's a dictionary with allotype-accession mappings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([('Aona-DQA1*2701', 'NHP00001'),\n",
       "  ('Aona-DQA1*27:01', 'NHP00001'),\n",
       "  ('Aona-DQA1*2702', 'NHP00002'),\n",
       "  ('Aona-DQA1*27:02', 'NHP00002'),\n",
       "  ('Aona-DQA1*2703', 'NHP00003')],\n",
       " [('HLA-A*01:01', 'HLA27590'),\n",
       "  ('HLA-A*01010101', 'HLA00001'),\n",
       "  ('HLA-A*010101', 'HLA00001'),\n",
       "  ('HLA-A*01011', 'HLA00001'),\n",
       "  ('HLA-A*0101', 'HLA00001')])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(ipd_hist.parsed_data.items())[:5], list(imgt_hist.parsed_data.items())[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, `obtain_mapping` combines these two dictionaries with an addition of manually entered mappings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('HLA-A*01:01', 'HLA27590'),\n",
       " ('HLA-A*01010101', 'HLA00001'),\n",
       " ('HLA-A*010101', 'HLA00001'),\n",
       " ('HLA-A*01011', 'HLA00001'),\n",
       " ('HLA-A*0101', 'HLA00001')]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapping = obtain_mapping('./tmp', ipd=ipd_hist, imgt=imgt_hist)\n",
    "list(mapping.items())[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Obtaining training observations\n",
    "\n",
    "Now, with the obtained mapping we can go ahead and preare a data source.\n",
    "Let's do this for `Bdata2013` since it's faster to download."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mInit signature:\u001b[0m\n",
       "\u001b[0mBdata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mdownload_dir\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mdownload_file_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'bdata.zip'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmapping\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIO\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'./mbae_resources/mapping.tsv'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m      Resource fetching and parsing Bdata2013.\n",
       "\u001b[0;31mInit docstring:\u001b[0m\n",
       ":param download_dir: Path to a directory where the resource will be downloaded.\n",
       ":param download_file_name: How to name a raw downloaded file.\n",
       ":param mapping: Initializing IEDB requires valid mapping (i.e., a dictionary) between allotypes and accessions.\n",
       "If not provided, this mapping will be obtained via IMGTHLAhistory and IPDMHChistory classes.\n",
       "\u001b[0;31mFile:\u001b[0m           ~/Projects/mbae_git/mbae_src/data/prepare.py\n",
       "\u001b[0;31mType:\u001b[0m           ABCMeta\n",
       "\u001b[0;31mSubclasses:\u001b[0m     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "?Bdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Bdata -- successfully initialized resource\n"
     ]
    }
   ],
   "source": [
    "bdata = Bdata(mapping=mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, it'll download the resource into a temporary directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Bdata -- downloaded resource from http://tools.iedb.org/static/main/binding_data_2013.zip\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/var/folders/h2/x9k131ls3dnf2j2xnm3bdxt00000gn/T/tmp7wlzjv_b/bdata.zip'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bdata.fetch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Bdata -- loaded resource; records: 186684\n",
      "INFO:root:Bdata -- filtered by peptide length; records: 186602\n",
      "WARNING:root:Bdata -- could not map 44 allotypes ['BoLA-AW10' 'BoLA-D18.4' 'BoLA-HD6' 'BoLA-JSP.1' 'BoLA-T2C' 'BoLA-T2a'\n",
      " 'BoLA-T2b' 'ELA-A1' 'H-2-Kbm8' 'H-2-Lq' 'HLA-A1' 'HLA-A11' 'HLA-A2'\n",
      " 'HLA-A24' 'HLA-A26' 'HLA-A3' 'HLA-A3/11' 'HLA-B27' 'HLA-B44' 'HLA-B51'\n",
      " 'HLA-B60' 'HLA-B7' 'HLA-B8' 'HLA-Cw1' 'HLA-Cw4' 'Mamu-A*01' 'Mamu-A*02'\n",
      " 'Mamu-A*07' 'Mamu-A*11' 'Mamu-A*2201' 'Mamu-A*2601' 'Mamu-B*01'\n",
      " 'Mamu-B*03' 'Mamu-B*04' 'Mamu-B*08' 'Mamu-B*1001' 'Mamu-B*17'\n",
      " 'Mamu-B*3901' 'Mamu-B*52' 'Mamu-B*6601' 'Mamu-B*8301' 'Mamu-B*8701'\n",
      " 'RT1-Bl' 'RT1A'] corresponding to 15453 records\n",
      "INFO:root:Bdata -- filtered out unmapped allotypes; records: 171149\n",
      "INFO:root:Bdata -- dropped unnecessary columns and removed duplicates; records 171149\n",
      "INFO:root:Bdata -- completed resource preparation; records: 171149\n"
     ]
    }
   ],
   "source": [
    "bdata.parse();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can inspect the parsed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accession</th>\n",
       "      <th>peptide</th>\n",
       "      <th>measurement</th>\n",
       "      <th>measurement_ord</th>\n",
       "      <th>inequality</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NHP00705</td>\n",
       "      <td>RRDYRRGL</td>\n",
       "      <td>778.583409</td>\n",
       "      <td>3</td>\n",
       "      <td>=</td>\n",
       "      <td>Bdata</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NHP00705</td>\n",
       "      <td>YHSNVKEL</td>\n",
       "      <td>18806.166640</td>\n",
       "      <td>1</td>\n",
       "      <td>=</td>\n",
       "      <td>Bdata</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NHP00705</td>\n",
       "      <td>AQFSPQYL</td>\n",
       "      <td>22203.186860</td>\n",
       "      <td>0</td>\n",
       "      <td>=</td>\n",
       "      <td>Bdata</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NHP00705</td>\n",
       "      <td>GDYKLVEI</td>\n",
       "      <td>87128.712870</td>\n",
       "      <td>0</td>\n",
       "      <td>&gt;</td>\n",
       "      <td>Bdata</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NHP00705</td>\n",
       "      <td>RGYVFQGL</td>\n",
       "      <td>87128.712870</td>\n",
       "      <td>0</td>\n",
       "      <td>&gt;</td>\n",
       "      <td>Bdata</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  accession   peptide   measurement  measurement_ord inequality source\n",
       "0  NHP00705  RRDYRRGL    778.583409                3          =  Bdata\n",
       "1  NHP00705  YHSNVKEL  18806.166640                1          =  Bdata\n",
       "2  NHP00705  AQFSPQYL  22203.186860                0          =  Bdata\n",
       "3  NHP00705  GDYKLVEI  87128.712870                0          >  Bdata\n",
       "4  NHP00705  RGYVFQGL  87128.712870                0          >  Bdata"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bdata.parsed_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, if we provide a valid directory path, raw downloaded files will be stored there.\n",
    "Note that one can omit the mapping creation: in this case, `Bdata` will make a call to the `obtain_mapping` internally. This will trigger the warning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Bdata -- found no \"allotype->accession\" mapping at ./mbae_resources/mapping.tsv; attempting to create a new one by fetching IPD-MHC and IMGT/HLA history\n",
      "INFO:root:IMGT/HLA history -- successfully initialized resource\n",
      "INFO:root:IMGT/HLA history -- downloaded resource from https://raw.githubusercontent.com/ANHIG/IMGTHLA/Latest/Allelelist_history.txt\n",
      "INFO:root:IMGT/HLA history -- successfully extracted mappings\n",
      "INFO:root:IPD-MHC history -- successfully initialized resource\n",
      "INFO:root:IPD-MHC history -- downloaded resource from https://raw.githubusercontent.com/ANHIG/IPDMHC/Latest/MHC.xml\n",
      "INFO:root:IPD-MHC history -- parsed xml tree\n",
      "INFO:root:IPD-MHC history -- successfully extracted mappings\n",
      "INFO:root:Bdata -- successfully initialized resource\n"
     ]
    }
   ],
   "source": [
    "bdata = Bdata(download_dir='./tmp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`IEDB` has the same interface, although its processing takes a bit more time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:IEDB -- found no \"allotype->accession\" mapping at ./mbae_resources/mapping.tsv; attempting to create a new one by fetching IPD-MHC and IMGT/HLA history\n",
      "INFO:root:IMGT/HLA history -- successfully initialized resource\n",
      "INFO:root:IMGT/HLA history -- downloaded resource from https://raw.githubusercontent.com/ANHIG/IMGTHLA/Latest/Allelelist_history.txt\n",
      "INFO:root:IMGT/HLA history -- successfully extracted mappings\n",
      "INFO:root:IPD-MHC history -- successfully initialized resource\n",
      "INFO:root:IPD-MHC history -- downloaded resource from https://raw.githubusercontent.com/ANHIG/IPDMHC/Latest/MHC.xml\n",
      "INFO:root:IPD-MHC history -- parsed xml tree\n",
      "INFO:root:IPD-MHC history -- successfully extracted mappings\n",
      "INFO:root:IEDB -- successfully initialized resource\n"
     ]
    }
   ],
   "source": [
    "iedb = IEDB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:IEDB -- downloaded resource from https://www.iedb.org/downloader.php?file_name=doc/mhc_ligand_full_single_file.zip\n",
      "INFO:root:IEDB -- loaded resource; records: 1883298\n",
      "INFO:root:IEDB -- filtered class I records; records: 1621944\n",
      "INFO:root:IEDB -- filtered quantitative assays; records: 184623\n",
      "INFO:root:IEDB -- filtered quantitative measurements; records: 157525\n",
      "INFO:root:IEDB -- filtered by evidence codes; records: 157525\n",
      "INFO:root:IEDB -- filtered by antigen type; records: 157521\n",
      "INFO:root:IEDB -- filtered by peptide length; records: 157111\n",
      "WARNING:root:IEDB -- could not map 46 allotypes ['Anpl-UAA*01' 'BF2*0401' 'BF2*1201' 'ELA-A1 class I' 'Eqca-N*00602'\n",
      " 'FLA-E*01801' 'H2-Db H155A mutant' 'H2-Db Y159F mutant'\n",
      " 'H2-Kb D77S, K89A mutant' 'H2-Kb E152A, R155Y, L156Y mutant'\n",
      " 'H2-Kb Y22F, M23I, E24S, D30N mutant' 'H2-Kb Y84A mutant'\n",
      " 'H2-Kb Y84C mutant' 'H2-Lq' 'H2-d class I' 'HLA class I'\n",
      " 'HLA-A*02:01 K66A mutant' 'HLA-A*02:01 K66A, E63Q mutant' 'HLA-A1'\n",
      " 'HLA-A11' 'HLA-A2' 'HLA-A24' 'HLA-A26' 'HLA-A3' 'HLA-A68'\n",
      " 'HLA-B*08:01 B:I66A mutant' 'HLA-B*08:01 E76C mutant' 'HLA-B27' 'HLA-B39'\n",
      " 'HLA-B40' 'HLA-B44' 'HLA-B51' 'HLA-B58' 'HLA-B60' 'HLA-B62' 'HLA-B7'\n",
      " 'HLA-B8' 'HLA-Cw1' 'HLA-Cw4' 'Mamu-B*001:01' 'Mamu-B*003:01'\n",
      " 'Ptal-N*01:01' 'RT1-Aa' 'SLA-1*04:01' 'SLA-3*02:02' 'Xela-UAAg'] corresponding to 1113 records\n",
      "INFO:root:IEDB -- filtered out unmapped allotypes; records: 155998\n",
      "INFO:root:IEDB -- dropped unnecessary columns and removed duplicates; records 153814\n",
      "INFO:root:IEDB -- completed resource preparation; records: 153814\n"
     ]
    }
   ],
   "source": [
    "iedb.fetch(), iedb.parse();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can separate the processed IEDB data into abundant and rare subsets, and each of the latter - into train and test subsets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A number of observations belonging to \"abundant\" allotypes: 150239\n",
      "A number of observations belonging to \"rare\" allotypes: 3575\n"
     ]
    }
   ],
   "source": [
    "abundant, rare = separate_abundant(iedb.parsed_data, rare_threshold=200)\n",
    "print(f'A number of observations belonging to \"abundant\" allotypes: {len(abundant)}')\n",
    "print(f'A number of observations belonging to \"rare\" allotypes: {len(rare)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A number of training examples: 127633\n",
      "A number of testing examples: 22606\n"
     ]
    }
   ],
   "source": [
    "abundant_train, abundant_test = separate_fraction(abundant, fraction=0.85, mode='observations')\n",
    "print(f'A number of training examples: {len(abundant_train)}')\n",
    "print(f'A number of testing examples: {len(abundant_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose one wants to separate a certain number of allotypes for testing.\n",
    "This is possible by providing `mode=accessions` to `separate_fraction`.\n",
    "\n",
    "For example, let's separate ten abundant allotypes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14084507042253522"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frac = 10 / len(abundant['accession'].unique())\n",
    "frac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A number of training examples: 131394\n",
      "A number of testing examples: 18845\n"
     ]
    }
   ],
   "source": [
    "abundant_train, abundant_test = separate_fraction(abundant, fraction=0.85, mode='allotypes')\n",
    "print(f'A number of training examples: {len(abundant_train)}')\n",
    "print(f'A number of testing examples: {len(abundant_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Obtaining allotype sequences\n",
    "\n",
    "Finally, let's prepare allotype sequences.\n",
    "For this, we'll first need to obtain a handful of accessions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_accessions = [\n",
    "    'ELA04973', 'HLA01173', 'HLA24796', 'HLA28069', 'BoLA03176',\n",
    "    'NHP01865', 'HLA27997', 'HLA27977', 'H-2-Kk', 'HLA25912',\n",
    "    'HLA00009', 'HLA27068', 'HLA16743', 'HLA27953', 'HLA15201',\n",
    "    'NHP00709', 'HLA00222', 'HLA28165', 'HLA25670', 'HLA25900']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:IPD-MHC sequences -- successfully initialized resource\n",
      "INFO:root:IMGT/HLA sequences -- successfully initialized resource\n"
     ]
    }
   ],
   "source": [
    "ipd_seqs = IPDMHCsequences()\n",
    "imgt_seqs = IMGTHLAsequences()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:IPD-MHC sequences -- downloaded resource from https://raw.githubusercontent.com/ANHIG/IPDMHC/Latest/MHC_prot.fasta\n",
      "INFO:root:IMGT/HLA sequences -- downloaded resource from https://raw.githubusercontent.com/ANHIG/IMGTHLA/Latest/hla_prot.fasta\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('/var/folders/h2/x9k131ls3dnf2j2xnm3bdxt00000gn/T/tmpxvsx_upn/MHC_prot.fasta',\n",
       " '/var/folders/h2/x9k131ls3dnf2j2xnm3bdxt00000gn/T/tmpjsd3334e/hla_prot.fasta')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ipd_seqs.fetch(), imgt_seqs.fetch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As previously, `parse` method is carrying out all the hard work.\n",
    "For both of the initialized objects, `parse` accepts a list of accessions.\n",
    "If the latter is not provided, all of the available sequences will be used. Since the later might take ages the user will be warned.\n",
    "\n",
    "By default, `parse` uses our alignment profile to excise binding region sequences.\n",
    "If the cutting is redundant, one can use `parse` with `profile_path=None` argument.\n",
    "We use `mafft --add` for an alignment; it works faster by allowing parallel execution via the `threads` argument.\n",
    "\n",
    "The method returns biopython's `SeqRecord` objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:IPD-MHC sequences -- loaded 10302 sequences\n",
      "INFO:root:IPD-MHC sequences -- filtered by accessions; 4 left (out of provided 5).\n",
      "INFO:root:IPD-MHC sequences -- 4 sequences were found in profile ./mbae_resources/binding_regions.fsa\n",
      "INFO:root:IPD-MHC sequences -- 1 will be aligned to ./mbae_resources/binding_regions.fsa\n",
      "Cutting sequences: 100%|██████████| 1/1 [00:05<00:00,  5.33s/it]\n",
      "INFO:root:IPD-MHC sequences -- finished parsing sequences; 5 in total\n",
      "INFO:root:IMGT/HLA sequences -- loaded 27840 sequences\n",
      "INFO:root:IMGT/HLA sequences -- filtered by accessions; 15 left (out of provided 15).\n",
      "INFO:root:IMGT/HLA sequences -- 3 sequences were found in profile ./mbae_resources/binding_regions.fsa\n",
      "INFO:root:IMGT/HLA sequences -- 12 will be aligned to ./mbae_resources/binding_regions.fsa\n",
      "Cutting sequences: 100%|██████████| 12/12 [01:12<00:00,  6.04s/it]\n",
      "INFO:root:IMGT/HLA sequences -- finished parsing sequences; 15 in total\n"
     ]
    }
   ],
   "source": [
    "ipd_seqs.parse(\n",
    "    accessions=[a for a in sample_accessions if 'HLA' not in a], \n",
    "    verbose=True, threads=6)\n",
    "imgt_seqs.parse(\n",
    "    accessions=[a for a in sample_accessions if 'HLA' in a], \n",
    "    verbose=True, threads=6);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that despite some sequences were lacking in the IPD-MHC dump, they were still included into the `parsed_data` due to being present in the alignment profile.\n",
    "\n",
    "We could've, as previously, use the `dump_data` method to save the sequences into fasta files.\n",
    "However, one probably wants these two groups of sequences in a single file.\n",
    "Thus, we'll simply use the `dump_data` helper function on merged `parsed_data` attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m\n",
       "\u001b[0m_dump_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mdump_path\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mresource_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mdump_data\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mBio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeqRecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeqRecord\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "A helper function to dump the resource's data.\n",
       "Consult with type annotations to check which data types are supported.\n",
       ":param dump_path: A path to dump to.\n",
       ":param resource_name: A name of the resource for formatting errors and logging messages.\n",
       ":param dump_data: Data to dump.\n",
       "\u001b[0;31mFile:\u001b[0m      ~/Projects/mbae_git/mbae_src/data/prepare.py\n",
       "\u001b[0;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "?_dump_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:NoResource -- saved parsed data to ./tmp/sequences.fasta\n"
     ]
    }
   ],
   "source": [
    "_dump_data('./tmp/sequences.fasta', 'NoResource', ipd_seqs.parsed_data + imgt_seqs.parsed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">BoLA03176 BoLA-2*00801\n",
      "SHSLRYFLTAVSRPGLGEPRFIIVGYVDDTQFVRFDSNTPNPRMEPRARWVEKEGPEYWD\n",
      "RETRNSKETAQTFRANLNTALGYYNQSEAGSHTVQEMYGCDVGPDGRLLRGFMQDAYDGR\n",
      "DYIALNEDLRSWTAADTAAQITKRKWEAAGDAETWRNYLEGRCVEWLRRYLENGKDALL\n",
      ">H-2-Kk H2-Kk\n",
      "PHSLRYFHTAVSRPGLGKPRFISVGYVDDTQFVRFDSDAENPRYEPRVRWMEQVEPEYWE\n",
      "RNTQIAKGNEQIFRVNLRTALRYYNQSAGGSHTFQRMYGCEVGSDWRLLRGYEQYAYDGC\n",
      "DYIALNEDLKTWTAADMAALITKHKWEQAGDAERDRAYLEGTCVEWLRRYLQLGNATLP\n",
      ">NHP00709 Patr-A*04:01\n",
      "SHSMRYFSTSVSRPGRGEPRFIAVGYVDDTQFVRFDSDAASQRMEPRAPWIEQEGPEYWD\n"
     ]
    }
   ],
   "source": [
    "! head ./tmp/sequences.fasta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finale.\n",
    "\n",
    "Now, hopefully, that is more than enough to get one going with the data preparation.\n",
    "\n",
    "Let's be nice and clean up the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "! rm -r tmp\n",
    "! rm ./mapping.tsv"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
