{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import operator as op\n",
    "import typing as t\n",
    "import copy\n",
    "from itertools import chain\n",
    "from collections import Counter\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "# from tensorflow._api.v1.keras import backend as K, layers, models, optimizers, \\\n",
    "#    activations, initializers\n",
    "from keras import backend as K, layers, models\n",
    "from Bio import SeqIO\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "from fn import F\n",
    "from fn.func import identity\n",
    "\n",
    "from sklab.data import preprocessing as pp\n",
    "from attention import core\n",
    "\n",
    "FLOAT_T = np.float32\n",
    "INT_T = np.int32\n",
    "\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class SequenceEncoder:\n",
    "    def __init__(self, alphabet: t.Iterable[str]):\n",
    "        unique = sorted(set(chain.from_iterable(alphabet)))\n",
    "        self._mapping = dict(\n",
    "            (val, key) for key, val in enumerate(unique, 1)\n",
    "        )\n",
    "        self._oov = len(self._mapping) + 1\n",
    "    \n",
    "    def __call__(self, sequence: t.Sequence[str]) -> np.ndarray:\n",
    "        encoded = (self._mapping.get(char, self._oov) for char in sequence)\n",
    "        return np.fromiter(encoded, INT_T, len(sequence))\n",
    "        \n",
    "    @property\n",
    "    def mapping(self) -> t.Mapping[str, int]:\n",
    "        return copy.deepcopy(self._mapping)\n",
    "    \n",
    "    @property\n",
    "    def oov(self) -> int:\n",
    "        return self._oov\n",
    "\n",
    "\n",
    "def expand_categories(categories: np.ndarray, dtype=FLOAT_T) -> np.ndarray:\n",
    "    ncat = categories.shape[0]\n",
    "    maxcat = categories.max()\n",
    "    expanded = np.zeros(maxcat*ncat, dtype=FLOAT_T).reshape((ncat, maxcat))\n",
    "    for i, j in enumerate(categories):\n",
    "        expanded[i,:j] = 1\n",
    "    return expanded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/abundant_train.tsv', sep='\\t')\n",
    "allotypes = {\n",
    "    seqrec.id: str(seqrec.seq) for seqrec in SeqIO.parse('data/allotype_binding_regions.faa', 'fasta')\n",
    "}\n",
    "consurf = pd.read_csv('data/consurf.tsv', sep='\\t')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['accession', 'allotype', 'article_affiliations', 'article_authors',\n",
       "       'article_chemical_list', 'article_date', 'article_id', 'article_title',\n",
       "       'bind_or_elution_id', 'category', 'collection', 'inequality',\n",
       "       'journal_title', 'measurement', 'measurement_ord', 'measurement_type',\n",
       "       'method', 'object_type', 'peptide', 'quantitative',\n",
       "       'reference_category_name', 'reference_type', 'source', 'species',\n",
       "       'submission_affiliations', 'submission_authors', 'submission_date',\n",
       "       'submission_id', 'submission_title', 'submitter_name', 'units'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['position', 'consurf_score'], dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "consurf.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9     116089\n",
       "10     32707\n",
       "8       5860\n",
       "11      3439\n",
       "13       311\n",
       "12       273\n",
       "15       223\n",
       "14       175\n",
       "18        34\n",
       "17        31\n",
       "20        14\n",
       "7          9\n",
       "16         6\n",
       "21         5\n",
       "19         3\n",
       "6          2\n",
       "5          2\n",
       "26         2\n",
       "23         1\n",
       "30         1\n",
       "Name: peptide, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# peptide length distribution\n",
    "\n",
    "train['peptide'].apply(len).value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "PEPTIDE_LEN = 16\n",
    "ALLOTYPE_LEN = 64\n",
    "\n",
    "# select ALLOTYPE_LEN most variable MHC positions (i.e. positions with large consurf scores)\n",
    "mhc_positions = consurf.sort_values('consurf_score', ascending=False).iloc[:ALLOTYPE_LEN,0].sort_values()\n",
    "# remove recods with overly long peptides\n",
    "train_filt = train[train['peptide'].apply(len) <= PEPTIDE_LEN]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "peptides_train = train_filt['peptide']\n",
    "accessions_train = train_filt['accession']\n",
    "categories_train = train_filt['measurement_ord']\n",
    "allotypes_train = (\n",
    "    F(map, allotypes.get)\n",
    "    >> (map, op.itemgetter(*mhc_positions))\n",
    "    >> list\n",
    ")(accessions_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "C    0.001142\n",
       "P    0.022825\n",
       "N    0.023451\n",
       "M    0.029600\n",
       "K    0.030530\n",
       "I    0.031085\n",
       "F    0.032541\n",
       "H    0.035138\n",
       "W    0.038424\n",
       "D    0.042060\n",
       "L    0.044233\n",
       "S    0.046269\n",
       "V    0.057988\n",
       "Y    0.060929\n",
       "T    0.065004\n",
       "Q    0.066136\n",
       "G    0.071495\n",
       "E    0.091462\n",
       "R    0.100311\n",
       "A    0.109377\n",
       "dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# allotype AA distribution\n",
    "allotype_train_aa_counts = Counter(chain.from_iterable(allotypes_train))\n",
    "(pd.Series(allotype_train_aa_counts) / sum(allotype_train_aa_counts.values())).sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "C    0.014703\n",
       "W    0.019917\n",
       "H    0.022215\n",
       "M    0.032078\n",
       "Q    0.032353\n",
       "D    0.037534\n",
       "N    0.038360\n",
       "E    0.043513\n",
       "P    0.046422\n",
       "G    0.047950\n",
       "K    0.052160\n",
       "R    0.053258\n",
       "Y    0.054931\n",
       "T    0.059862\n",
       "F    0.059978\n",
       "S    0.063748\n",
       "I    0.068264\n",
       "V    0.068847\n",
       "A    0.068972\n",
       "L    0.114938\n",
       "dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# peptide AA distribution\n",
    "peptide_train_aa_counts = Counter(chain.from_iterable(peptides_train))\n",
    "(pd.Series(peptide_train_aa_counts) / sum(peptide_train_aa_counts.values())).sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "allotype_aa = chain.from_iterable(allotypes_train)\n",
    "peptide_aa = chain.from_iterable(peptides_train)\n",
    "seqencoder = SequenceEncoder(\n",
    "    (F(chain) >> (filter, lambda aa: aa != '-'))(allotype_aa, peptide_aa)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ilia/storage/ksi/melanoma/attention/sklab/data/preprocessing.py:118: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  op.setitem(stacked, [i, *slices_], op.getitem(arr, slices_))\n",
      "/home/ilia/storage/ksi/melanoma/attention/sklab/data/preprocessing.py:119: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  op.setitem(mask, [i, *slices_], True)\n"
     ]
    }
   ],
   "source": [
    "peptides_enc_train, peptides_mask_train = pp.stack(\n",
    "    [seqencoder(pep) for pep in peptides_train],\n",
    "    shape=(PEPTIDE_LEN,), dtype=INT_T, filler=0\n",
    ")\n",
    "allotypes_enc_train, allotypes_mask_train = pp.stack(\n",
    "    [seqencoder(allo) for allo in allotypes_train],\n",
    "    shape=(ALLOTYPE_LEN,), dtype=INT_T, filler=0 \n",
    ")\n",
    "categories_enc_train = expand_categories(categories_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q Tensor(\"Shape:0\", shape=(3,), dtype=int32)\n",
      "splits Tensor(\"strided_slice:0\", shape=(), dtype=int32) Tensor(\"strided_slice_1:0\", shape=(), dtype=int32) Tensor(\"strided_slice_2:0\", shape=(), dtype=int32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor 'dense_4/Reshape_2:0' shape=(?, 16, 16) dtype=float32>,\n",
       " <tf.Tensor 'lambda_7/transpose:0' shape=(?, ?, 4, ?) dtype=float32>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = 256\n",
    "emb_d = 16\n",
    "depth = 3\n",
    "r = 4\n",
    "ffn_hid = emb_d * r\n",
    "ffn_act = 'elu'\n",
    "dropout = 0.1\n",
    "\n",
    "input_allotypes = layers.Input(\n",
    "    shape=(ALLOTYPE_LEN,), name='input_allotypes', dtype='int32'\n",
    ")\n",
    "input_peptides = layers.Input(\n",
    "    shape=(PEPTIDE_LEN,), name='input_peptides', dtype='int32'\n",
    ")\n",
    "\n",
    "embeddings = layers.Embedding(\n",
    "    input_dim=seqencoder.oov+1, output_dim=emb_d,\n",
    "    mask_zero=False, name='embeddings'\n",
    ")\n",
    "\n",
    "# embedded_allotypes = layers.Lambda(\n",
    "#     identity, output_shape=(ALLOTYPE_LEN, emb_d), name='embed_allotypes'\n",
    "# )(embeddings(input_allotypes))\n",
    "embedded_peptides = layers.Lambda(\n",
    "    identity, output_shape=(PEPTIDE_LEN, emb_d), name='embed_peptides'\n",
    ")(embeddings(input_peptides))\n",
    "\n",
    "attention = core.ScaledDotProductAttention(dropout)\n",
    "mhattention = core.MultiHeadAttention(attention, PEPTIDE_LEN, PEPTIDE_LEN, r, emb_d // r)\n",
    "\n",
    "# mhattention(PEPTIDE_LEN, PEPTIDE_LEN, embedded_peptides, embedded_peptides, embedded_peptides)\n",
    "mhattention(embedded_peptides, embedded_peptides, embedded_peptides)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(16), Dimension(16)])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedded_peptides.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
