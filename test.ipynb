{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import operator as op\n",
    "import typing as t\n",
    "import copy\n",
    "from itertools import chain\n",
    "from collections import Counter\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "# from tensorflow._api.v1.keras import backend as K, layers, models, optimizers, \\\n",
    "#    activations, initializers\n",
    "from keras import backend as K, layers, models\n",
    "from Bio import SeqIO\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "from fn import F\n",
    "from fn.func import identity\n",
    "\n",
    "from sklab.data import preprocessing as pp\n",
    "from sklab.attention import core, util\n",
    "\n",
    "FLOAT_T = np.float32\n",
    "INT_T = np.int32\n",
    "\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__init__.py  \u001b[1m\u001b[34m__pycache__\u001b[m\u001b[m/ \u001b[1m\u001b[34mattention\u001b[m\u001b[m/   \u001b[1m\u001b[34mdata\u001b[m\u001b[m/        \u001b[1m\u001b[34mstats\u001b[m\u001b[m/\r\n"
     ]
    }
   ],
   "source": [
    "ls sklab/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class SequenceEncoder:\n",
    "    def __init__(self, alphabet: t.Iterable[str]):\n",
    "        unique = sorted(set(chain.from_iterable(alphabet)))\n",
    "        self._mapping = dict(\n",
    "            (val, key) for key, val in enumerate(unique, 1)\n",
    "        )\n",
    "        self._oov = len(self._mapping) + 1\n",
    "    \n",
    "    def __call__(self, sequence: t.Sequence[str]) -> np.ndarray:\n",
    "        encoded = (self._mapping.get(char, self._oov) for char in sequence)\n",
    "        return np.fromiter(encoded, INT_T, len(sequence))\n",
    "        \n",
    "    @property\n",
    "    def mapping(self) -> t.Mapping[str, int]:\n",
    "        return copy.deepcopy(self._mapping)\n",
    "    \n",
    "    @property\n",
    "    def oov(self) -> int:\n",
    "        return self._oov\n",
    "\n",
    "\n",
    "def expand_categories(categories: np.ndarray, dtype=FLOAT_T) -> np.ndarray:\n",
    "    ncat = categories.shape[0]\n",
    "    maxcat = categories.max()\n",
    "    expanded = np.zeros(maxcat*ncat, dtype=FLOAT_T).reshape((ncat, maxcat))\n",
    "    for i, j in enumerate(categories):\n",
    "        expanded[i,:j] = 1\n",
    "    return expanded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/abundant_train.tsv', sep='\\t')\n",
    "allotypes = {\n",
    "    seqrec.id: str(seqrec.seq) for seqrec in SeqIO.parse('data/allotype_binding_regions.faa', 'fasta')\n",
    "}\n",
    "consurf = pd.read_csv('data/consurf.tsv', sep='\\t')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['accession', 'allotype', 'article_affiliations', 'article_authors',\n",
       "       'article_chemical_list', 'article_date', 'article_id', 'article_title',\n",
       "       'bind_or_elution_id', 'category', 'collection', 'inequality',\n",
       "       'journal_title', 'measurement', 'measurement_ord', 'measurement_type',\n",
       "       'method', 'object_type', 'peptide', 'quantitative',\n",
       "       'reference_category_name', 'reference_type', 'source', 'species',\n",
       "       'submission_affiliations', 'submission_authors', 'submission_date',\n",
       "       'submission_id', 'submission_title', 'submitter_name', 'units'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['position', 'consurf_score'], dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "consurf.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9     116089\n",
       "10     32707\n",
       "8       5860\n",
       "11      3439\n",
       "13       311\n",
       "12       273\n",
       "15       223\n",
       "14       175\n",
       "18        34\n",
       "17        31\n",
       "20        14\n",
       "7          9\n",
       "16         6\n",
       "21         5\n",
       "19         3\n",
       "6          2\n",
       "5          2\n",
       "26         2\n",
       "23         1\n",
       "30         1\n",
       "Name: peptide, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# peptide length distribution\n",
    "\n",
    "train['peptide'].apply(len).value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "PEPTIDE_LEN = 16\n",
    "ALLOTYPE_LEN = 64\n",
    "\n",
    "# select ALLOTYPE_LEN most variable MHC positions (i.e. positions with large consurf scores)\n",
    "mhc_positions = consurf.sort_values('consurf_score', ascending=False).iloc[:ALLOTYPE_LEN,0].sort_values()\n",
    "# remove recods with overly long peptides\n",
    "train_filt = train[train['peptide'].apply(len) <= PEPTIDE_LEN]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "peptides_train = train_filt['peptide']\n",
    "accessions_train = train_filt['accession']\n",
    "categories_train = train_filt['measurement_ord']\n",
    "allotypes_train = (\n",
    "    F(map, allotypes.get)\n",
    "    >> (map, op.itemgetter(*mhc_positions))\n",
    "    >> list\n",
    ")(accessions_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "C    0.001142\n",
       "P    0.022825\n",
       "N    0.023451\n",
       "M    0.029600\n",
       "K    0.030530\n",
       "I    0.031085\n",
       "F    0.032541\n",
       "H    0.035138\n",
       "W    0.038424\n",
       "D    0.042060\n",
       "L    0.044233\n",
       "S    0.046269\n",
       "V    0.057988\n",
       "Y    0.060929\n",
       "T    0.065004\n",
       "Q    0.066136\n",
       "G    0.071495\n",
       "E    0.091462\n",
       "R    0.100311\n",
       "A    0.109377\n",
       "dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# allotype AA distribution\n",
    "allotype_train_aa_counts = Counter(chain.from_iterable(allotypes_train))\n",
    "(pd.Series(allotype_train_aa_counts) / sum(allotype_train_aa_counts.values())).sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "C    0.014703\n",
       "W    0.019917\n",
       "H    0.022215\n",
       "M    0.032078\n",
       "Q    0.032353\n",
       "D    0.037534\n",
       "N    0.038360\n",
       "E    0.043513\n",
       "P    0.046422\n",
       "G    0.047950\n",
       "K    0.052160\n",
       "R    0.053258\n",
       "Y    0.054931\n",
       "T    0.059862\n",
       "F    0.059978\n",
       "S    0.063748\n",
       "I    0.068264\n",
       "V    0.068847\n",
       "A    0.068972\n",
       "L    0.114938\n",
       "dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# peptide AA distribution\n",
    "peptide_train_aa_counts = Counter(chain.from_iterable(peptides_train))\n",
    "(pd.Series(peptide_train_aa_counts) / sum(peptide_train_aa_counts.values())).sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "allotype_aa = chain.from_iterable(allotypes_train)\n",
    "peptide_aa = chain.from_iterable(peptides_train)\n",
    "seqencoder = SequenceEncoder(\n",
    "    (F(chain) >> (filter, lambda aa: aa != '-'))(allotype_aa, peptide_aa)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ilia/Code/utils/sklab/data/preprocessing.py:118: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  op.setitem(stacked, [i, *slices_], op.getitem(arr, slices_))\n",
      "/Users/ilia/Code/utils/sklab/data/preprocessing.py:119: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  op.setitem(mask, [i, *slices_], True)\n"
     ]
    }
   ],
   "source": [
    "peptides_enc_train, peptides_mask_train = pp.stack(\n",
    "    [seqencoder(pep) for pep in peptides_train],\n",
    "    shape=(PEPTIDE_LEN,), dtype=INT_T, filler=0\n",
    ")\n",
    "allotypes_enc_train, allotypes_mask_train = pp.stack(\n",
    "    [seqencoder(allo) for allo in allotypes_train],\n",
    "    shape=(ALLOTYPE_LEN,), dtype=INT_T, filler=0 \n",
    ")\n",
    "categories_enc_train = expand_categories(categories_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "batch = 256\n",
    "emb_d = 8\n",
    "depth = 3\n",
    "r = 4\n",
    "ffn_hid = emb_d * r\n",
    "ffn_act = 'elu'\n",
    "dropout = 0.1\n",
    "\n",
    "input_allotypes = layers.Input(\n",
    "    shape=(ALLOTYPE_LEN,), name='input_allotypes', dtype='int32'\n",
    ")\n",
    "input_peptides = layers.Input(\n",
    "    shape=(PEPTIDE_LEN,), name='input_peptides', dtype='int32'\n",
    ")\n",
    "\n",
    "embeddings = layers.Embedding(\n",
    "    input_dim=seqencoder.oov+1, output_dim=emb_d,\n",
    "    mask_zero=False, name='embeddings'\n",
    ")\n",
    "\n",
    "# embedded_allotypes = layers.Lambda(\n",
    "#     identity, output_shape=(ALLOTYPE_LEN, emb_d), name='embed_allotypes'\n",
    "# )(embeddings(input_allotypes))\n",
    "embedded_peptides = layers.Lambda(\n",
    "    identity, output_shape=(lambda s: [s[0], s[1], s[2]]), name='embed_peptides'\n",
    ")(embeddings(input_peptides))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(16), Dimension(8)])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedded_peptides.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keras tensor\n",
    "KTensor = t.NewType('KTensor', tf.Tensor)\n",
    "\n",
    "# TODO find a way to specify a list of length 3 as input and a list\n",
    "# TODO of length 2 as output\n",
    "QKVAttention = t.Callable[[t.List[KTensor]], t.List[KTensor]]\n",
    "\n",
    "# TODO implement as Layer and Model objects\n",
    "\n",
    "\n",
    "\n",
    "class LayerNormalisation(layers.Layer):\n",
    "\n",
    "    def __init__(self, eps=K.epsilon(), **kwargs):\n",
    "        self.eps = eps\n",
    "        self.gamma = None  # set in LaterNormalisation.__build__\n",
    "        self.beta = None  # set in LaterNormalisation.__build__\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.gamma = self.add_weight(\n",
    "            name='gamma', shape=input_shape[-1:],\n",
    "            initializer=initializers.Ones(), trainable=True\n",
    "        )\n",
    "        self.beta = self.add_weight(\n",
    "            name='beta', shape=input_shape[-1:],\n",
    "            initializer=initializers.Zeros(), trainable=True\n",
    "        )\n",
    "        super().build(input_shape)\n",
    "\n",
    "    def call(self, inputs, **kwargs) -> KTensor:\n",
    "        \"\"\"\n",
    "        :param inputs: a Keras tensor\n",
    "        :param kwargs:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        x = inputs\n",
    "        mean = K.mean(x, axis=-1, keepdims=True)\n",
    "        std = K.std(x, axis=-1, keepdims=True)\n",
    "        return self.gamma * (x - mean) / (std + self.eps) + self.beta\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape\n",
    "\n",
    "\n",
    "class BatchDot(layers.Layer):\n",
    "    \"\"\"\n",
    "    A wrapper around keras.backend.batch_dot\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, axes: t.Optional[t.Union[int, t.Tuple[int, int]]], **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.axes = axes\n",
    "\n",
    "    def call(self, inputs, **kwargs) -> KTensor:\n",
    "        return layers.Lambda(\n",
    "            lambda x: K.batch_dot(x[0], x[1], axes=self.axes)\n",
    "        )(inputs)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        x_shape, y_shape = input_shape\n",
    "        x_ndim, y_ndim = map(len, input_shape)\n",
    "        if x_ndim < 2 or y_ndim < 2:\n",
    "            raise ValueError(\n",
    "                f'Can not do batch_dot on inputs with rank < 2. Received inputs '\n",
    "                f'with shapes {x_shape} and {y_shape}.'\n",
    "            )\n",
    "        x_batch = x_shape[0]\n",
    "        y_batch = y_shape[0]\n",
    "        if not (x_batch is None or y_batch is None) and x_batch != y_batch:\n",
    "            raise ValueError(\n",
    "                f'Can not do batch_dot on inputs with different batch sizes. '\n",
    "                f'Received inputs with shapes {x_shape} and {y_shape}.'\n",
    "            )\n",
    "        # resolve different axes cases\n",
    "        axes = (\n",
    "            [self.axes, self.axes] if isinstance(self.axes, int) else\n",
    "            list(self.axes) if self.axes is not None else\n",
    "            [x_ndim - 1, y_ndim - 1] if y_ndim == 2 else\n",
    "            [x_ndim - 1, y_ndim - 2]\n",
    "        )\n",
    "        # make sure all axes are either None or integers\n",
    "        # TODO rewrite this message and condition\n",
    "        if any([isinstance(axis, (list, tuple)) for axis in axes]):\n",
    "            raise ValueError(\n",
    "                f'Multiple target dimensions are not supported. '\n",
    "                f'Expected: None, int, (int, int). Received: {axes}.'\n",
    "            )\n",
    "        # resolve negative indices\n",
    "        axes_noneg = [\n",
    "            axes[0] if axes[0] >= 0 else axes[0] + x_ndim,\n",
    "            axes[1] if axes[1] >= 0 else axes[1] + y_ndim\n",
    "        ]\n",
    "        # make sure we are not multiplying along the batch axis\n",
    "        if 0 in axes:\n",
    "            raise ValueError(\n",
    "                'Can not perform batch_dot over axis 0. If your inputs are not '\n",
    "                'batched, add a dummy batch dimension to your inputs using '\n",
    "                'K.expand_dims(x, 0)'\n",
    "            )\n",
    "        # use a dummy Dot layer to calculate output shape\n",
    "        dot = layers.Dot(axes_noneg)\n",
    "        return dot.compute_output_shape(input_shape)\n",
    "\n",
    "\n",
    "class SplitHeads(layers.Layer):\n",
    "    # TODO add docs and argument checks\n",
    "    def __init__(self, r: int, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.r = r\n",
    "\n",
    "    def _split(self, x: tf.Tensor) -> tf.Tensor:\n",
    "        return util.split_heads(self.r, x)\n",
    "\n",
    "    def call(self, inputs: KTensor, **kwargs) -> KTensor:\n",
    "        return layers.Lambda(\n",
    "            self._split, output_shape=self.compute_output_shape\n",
    "        )(inputs)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        b, l, d = input_shape\n",
    "        d_r = d // self.r\n",
    "        rb = None if b is None else b * self.r\n",
    "        return rb, l, d_r\n",
    "\n",
    "\n",
    "class MergeHeads(layers.Layer):\n",
    "    # TODO add docs and argument checks\n",
    "    def __init__(self, r: int, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.r = r\n",
    "\n",
    "    def _merge(self, x: tf.Tensor) -> tf.Tensor:\n",
    "        return util.merge_heads(self.r, x)\n",
    "\n",
    "    def call(self, inputs, **kwargs):\n",
    "        return layers.Lambda(\n",
    "            self._merge, output_shape=self.compute_output_shape\n",
    "        )(inputs)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        rb, l, d_r = input_shape\n",
    "        d = self.r * d_r\n",
    "        b = None if rb is None else rb // self.r\n",
    "        return b, l, d\n",
    "    \n",
    "\n",
    "class GroupAttentions(layers.Layer):\n",
    "    # TODO add docs and argument checks\n",
    "    def __init__(self, r: int, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.r = r\n",
    "\n",
    "    def _group(self, x: tf.Tensor) -> tf.Tensor:\n",
    "        return util.group_attentions(self.r, x)\n",
    "\n",
    "    def call(self, inputs, **kwargs) -> KTensor:\n",
    "        return layers.Lambda(\n",
    "            self._group, output_shape=self.compute_output_shape\n",
    "        )(inputs)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        rb, l_q, l_k = input_shape\n",
    "        b = None if rb is None else rb // self.r\n",
    "        return b, l_q, self.r, l_k\n",
    "\n",
    "\n",
    "class ScaledDotProductAttention(layers.Layer):\n",
    "    \"\"\"\n",
    "    Build a subgraph for scaled dot product attention.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, dropout: float, return_drop=False, **kwargs):\n",
    "        \"\"\"\n",
    "        :param dropout:\n",
    "        :param return_drop: return attention matrix after dropout\n",
    "        :param kwargs:\n",
    "        \"\"\"\n",
    "        super().__init__(**kwargs)\n",
    "        self.dropout = layers.Dropout(dropout) if dropout else None\n",
    "        self.return_drop = return_drop\n",
    "\n",
    "    def call(self, inputs: t.List[KTensor], **kwargs) -> t.List[KTensor]:\n",
    "        q, k, v = inputs\n",
    "        return self._call(q, k, v)\n",
    "\n",
    "    # TODO merge call and _call\n",
    "    def _call(self, q: KTensor, k: KTensor, v: KTensor) -> t.List[KTensor]:\n",
    "        r\"\"\"\n",
    "        Argument shape legend: b - batch, l - length (number of entries in a\n",
    "        sequence), d â€“ entry length (embedding dimensions)\n",
    "        Given:\n",
    "            $ Q \\in {R}^{ {l}_{q} \\times d } $\n",
    "            $ K \\in {R}^{ {l}_{k} \\times d } $\n",
    "        the scale dot-product attention matrix is defined as\n",
    "        $$\n",
    "        A = softmax( \\frac{ Q \\times {K}^{T}) }{ \\sqrt{d} } )\n",
    "        $$\n",
    "        Given a value $ V \\in {R}^{ {l}_{v} \\times d } $, such that\n",
    "        ${l}_{v} = {l}_{k}$ this layer calculates returns both the attention\n",
    "         matrix and the $ A \\times V $ product\n",
    "        :param q: a query tensor of shape [b, l_q,  d]\n",
    "        :param k: a key tensor of shape [b, l_k, d]\n",
    "        :param v: a value tensor of shape [b, l_v, d], such that l_v == l_k\n",
    "        :return: $ A \\times V $ tensor of shape [b, l_v, d], attention\n",
    "        matrix of shape [b, l_q, l_k]\n",
    "        \"\"\"\n",
    "        d = K.shape(q)[-1]\n",
    "        scaling_factor = K.sqrt(K.cast(d, dtype=K.floatx()))\n",
    "        # Q \\times {K}^{T} => shape = [b, l_q, l_k]\n",
    "        similarity = BatchDot(axes=(2, 2))([q, k])\n",
    "        att_scaled = layers.Activation('softmax')(similarity / scaling_factor)\n",
    "        att_drop = self.dropout(att_scaled) if self.dropout else att_scaled\n",
    "        # A \\times V => shape = [b, l_v, d]\n",
    "        att_v = BatchDot(axes=None)([att_drop, v])\n",
    "        return [att_v, att_drop if self.return_drop else att_scaled]\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        q_shape, k_shape, v_shape = input_shape\n",
    "        b_q, l_q, d_q = q_shape\n",
    "        b_k, l_k, d_k = k_shape\n",
    "        b_v, l_v, d_v = v_shape\n",
    "        # TODO check that:\n",
    "        #     1. b_q == b_k == b_v (if they are not None)\n",
    "        #     2. d_q == d_k; these must not be None\n",
    "        #     3. l_k == l_v; these must not be None\n",
    "        #     4. d_v is not None\n",
    "        # if not (b_q is None or b_k is None) and b_q != b_k:\n",
    "        #     raise ValueError(\n",
    "        #         '...'\n",
    "        #     )\n",
    "        # if not (d_q is None or d_k is None) and d_q != d_k:\n",
    "        #     raise ValueError(\n",
    "        #         '...'\n",
    "        #     )\n",
    "        product_shape = (b_q, l_v, d_v)\n",
    "        attention_shape = (b_q, l_q, l_k)\n",
    "        return [product_shape, attention_shape]\n",
    "\n",
    "\n",
    "class MultiHeadAttention(layers.Layer):\n",
    "    \"\"\"\n",
    "    Transform a single-headed attention block into a multi-headed attention\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, attention: QKVAttention, r: int, d_r: int, **kwargs):\n",
    "        # TODO check d and r compatibility\n",
    "        # TODO check dropout\n",
    "        super().__init__(**kwargs)\n",
    "        self.attention = attention\n",
    "        self.r = r\n",
    "        self.d_r = d_r\n",
    "        self.d = d_r * r\n",
    "        # head splitter and merger\n",
    "        self.splitter = SplitHeads(self.r)\n",
    "        self.merger = MergeHeads(self.r)\n",
    "        self.att_grouper = GroupAttentions(self.r)\n",
    "        # create linear mappings for Q, K and V\n",
    "        self.q_map = layers.Dense(self.d, use_bias=False)\n",
    "        self.k_map = layers.Dense(self.d, use_bias=False)\n",
    "        self.v_map = layers.Dense(self.d, use_bias=False)\n",
    "        # create a linear mapping for A \\times V\n",
    "        self.att_v_map = layers.Dense(self.d, use_bias=False)\n",
    "\n",
    "    def call(self, inputs, **kwargs) -> t.List[KTensor]:\n",
    "        q, k, v = inputs\n",
    "        return self._call(q, k, v)\n",
    "\n",
    "    def _call(self, q: KTensor, k: KTensor, v: KTensor) -> t.List[KTensor]:\n",
    "        \"\"\"\n",
    "        :param q:\n",
    "        :param k:\n",
    "        :param v:\n",
    "        :return: returns a grouped attention matrix (for more details see\n",
    "        util.group_attentions)\n",
    "        \"\"\"\n",
    "        # transform subspaces and split heads\n",
    "        q_split = self.splitter(self.q_map(q))\n",
    "        k_split = self.splitter(self.k_map(k))\n",
    "        v_split = self.splitter(self.v_map(v))\n",
    "        # calculate attention heads\n",
    "        att_v_split, att_split = self.attention([q_split, k_split, v_split])\n",
    "        # merge heads and apply a linear map\n",
    "        att_v_merged = self.merger(att_v_split)\n",
    "        att_v = self.att_v_map(att_v_merged)\n",
    "        att_groups = self.att_grouper(att_split)\n",
    "        return [att_v, att_groups]\n",
    "    \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        q_shape, k_shape, v_shape = input_shape\n",
    "        q_split_shape = self.splitter.compute_output_shape(q_shape)\n",
    "        k_split_shape = self.splitter.compute_output_shape(k_shape)\n",
    "        v_split_shape = self.splitter.compute_output_shape(v_shape)\n",
    "        att_v_split_shape, att_split_shape = self.attention.compute_output_shape(\n",
    "            [q_split_shape, k_split_shape, v_split_shape]\n",
    "        )\n",
    "        att_v_merge_shape = self.merger.compute_output_shape(att_v_split_shape)\n",
    "        att_v_shape = self.att_v_map.compute_output_shape(att_v_merge_shape)\n",
    "        att_groups_shape = self.att_grouper.compute_output_shape(att_split_shape)\n",
    "        return [att_v_shape, att_groups_shape]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "ph_x = K.placeholder(shape=(None, PEPTIDE_LEN, emb_d))\n",
    "ph_y = K.placeholder(shape=(None, ALLOTYPE_LEN, emb_d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'batch_dot_1/lambda_1/MatMul:0' shape=(?, 16, 64) dtype=float32>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ph_z = BatchDot([2, 2])([ph_x, ph_y])\n",
    "ph_z "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'batch_dot_2/lambda_2/MatMul:0' shape=(?, 16, 8) dtype=float32>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BatchDot(None)([ph_z, ph_y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'MatMul:0' shape=(?, 16, 8) dtype=float32>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K.batch_dot(ph_z, ph_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((None, 16, 2), (None, 16, 8))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_split = SplitHeads(4)(ph_x)\n",
    "_merge = MergeHeads(4)(_split)\n",
    "\n",
    "K.int_shape(_split), K.int_shape(_merge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'dense_5/add:0' shape=(?, 16, 8) dtype=float32>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layers.Dense(8)(_merge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention = ScaledDotProductAttention(dropout)\n",
    "mhattention = MultiHeadAttention(attention, r, emb_d // r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'scaled_dot_product_attention_2/batch_dot_4/lambda_6/MatMul:0' shape=(?, 16, 8) dtype=float32>,\n",
       " <tf.Tensor 'scaled_dot_product_attention_2/activation_1/truediv:0' shape=(?, 16, 64) dtype=float32>]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention([ph_x, ph_y, ph_y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(None, 64, 8), (None, 16, 64)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(map(K.int_shape, attention([ph_x, ph_y, ph_y])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(None, 16, 8), (None, 16, 16)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(map(K.int_shape, attention([ph_x, ph_x, ph_x])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'multi_head_attention_2/dense_9/Reshape_2:0' shape=(?, 16, 8) dtype=float32>,\n",
       " <tf.Tensor 'multi_head_attention_2/group_attentions_2/lambda_17/transpose:0' shape=(?, ?, 4, ?) dtype=float32>]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mhattention([ph_x, ph_x, ph_x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(None, 16, 8), (None, 16, 4, 16)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(map(K.int_shape, mhattention([ph_x, ph_x, ph_x])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
